{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6f017e-8ebe-49d5-86ff-01f1bde7966b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import git\n",
    "import pathlib\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, layers\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "PROJ_ROOT_PATH = pathlib.Path(git.Repo('.', search_parent_directories=True).working_tree_dir)\n",
    "PROJ_ROOT =  str(PROJ_ROOT_PATH)\n",
    "if PROJ_ROOT not in sys.path:\n",
    "    sys.path.append(PROJ_ROOT)\n",
    "\n",
    "import libs.model_archs\n",
    "import libs.utils\n",
    "from libs.constants import MODELS_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70acd768-e561-4dab-815e-95825fddbab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit GPU growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581d2035-dfb5-4fb2-b0eb-d8d9ee575419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import libs.model_archs\n",
    "import libs.utils\n",
    "from libs.seeds import load_model_seeds\n",
    "model_seeds = load_model_seeds()\n",
    "model_seeds = [model_seeds[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7921b68f-1c07-4cbd-9c89-22b4b3a690bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define dataset and model architecture\n",
    "dataset = \"cifar10\"\n",
    "model_arch = \"vgg16F\" # \"fcA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5f337d-dd94-4ae8-8480-48a4cd58a710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "dataset_loader = getattr(libs.utils, 'prepare_'+dataset)\n",
    "(x_train, y_train), (x_test, y_test) = dataset_loader()\n",
    "\n",
    "train_images_subset = x_train[0:1000] # out of 60000\n",
    "train_labels_subset = y_train[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d306f8-c581-42ec-8454-88e7ca83f0dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set q_aware-training hyperparameters\n",
    "# q_aware_batch_size = 500\n",
    "# q_aware_n_epochs = 5\n",
    "\n",
    "result = {}\n",
    "for q_aware_batch_size in [128]:#, 256, 512, 1024]:\n",
    "    for q_aware_n_epochs in [1]:#,2,5, 10, 20, 50]:\n",
    "        for seed in model_seeds:\n",
    "            # global seed\n",
    "            # seed = model_seeds[0]\n",
    "            tf.random.set_seed(seed)\n",
    "            np.random.seed(seed)\n",
    "\n",
    "            # load model\n",
    "            model_type = dataset + \"--\" + model_arch\n",
    "            model_instance = model_type + \"-\" + str(seed)\n",
    "            model_filename = model_instance + \".h5\"\n",
    "            model_subdir = pathlib.Path(MODELS_FOLDER / model_arch)\n",
    "            model_file = str(pathlib.Path(model_subdir/ model_filename))\n",
    "            model = models.load_model(model_file)\n",
    "\n",
    "            # create quantization aware model\n",
    "            import tensorflow_model_optimization as tfmot\n",
    "\n",
    "            # resulting model is quantization aware but not quantized (e.g. the weights are float32 instead of int8)\n",
    "            quantize_model = tfmot.quantization.keras.quantize_model\n",
    "\n",
    "            # q_aware stands for for quantization aware.\n",
    "            q_aware_model = quantize_model(model)\n",
    "            q_aware_model._name = \"q_aware_\"+model.name\n",
    "\n",
    "            # `quantize_model` requires a recompile.\n",
    "            q_aware_model.compile(optimizer='adam',\n",
    "                                  loss=keras.losses.categorical_crossentropy,\n",
    "                                  metrics=['accuracy'])\n",
    "\n",
    "            # q_aware_model.summary()\n",
    "\n",
    "            # finetune q_aware_model\n",
    "            q_aware_model.fit(train_images_subset, \n",
    "                              train_labels_subset,\n",
    "                              batch_size=q_aware_batch_size, \n",
    "                              epochs=q_aware_n_epochs, \n",
    "                              verbose=False,\n",
    "                              validation_split=0.1)\n",
    "\n",
    "            # # evaluate original model\n",
    "            # _ , original_acc = model.evaluate(x_test, \n",
    "            #                        y_test, \n",
    "            #                        batch_size=32,\n",
    "            #                       verbose=False)\n",
    "            # result.setdefault(model_type,{}).setdefault(seed, {}).setdefault(\"acc\", original_acc)\n",
    "\n",
    "            # evaluate quantized model\n",
    "            _, q_aware_acc = q_aware_model.evaluate(x_test, \n",
    "                                   y_test, \n",
    "                                   batch_size=32,\n",
    "                                  verbose=False)\n",
    "\n",
    "            q_aware_model_arch = \"q_aware_\" + model_arch\n",
    "            q_aware_model_type = dataset + \"--\" + q_aware_model_arch\n",
    "            result.setdefault(q_aware_model_type,{}).setdefault(q_aware_batch_size,{}).setdefault(q_aware_n_epochs,{}).setdefault(seed, {}).setdefault(\"acc\", q_aware_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90da5978-fe36-4370-b110-8991a2ee34cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict({(i,j,k): result[i][j][k] # {1437: {'acc': 0.8871999979019165}, ...}\n",
    "                             for i in result.keys() #['fashion--q_aware_lenetA]\n",
    "                             for j in result[i].keys() #[32]\n",
    "                             for k in result[i][j].keys() #[1,2,5,10,20,50]\n",
    "                             },  \n",
    "                             orient='index')\n",
    "\n",
    "df = df.applymap(lambda x: x['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c51ae0-58d8-44d2-b0ba-7f40ae1dbe6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1360bd16-58a2-4b02-ac64-2ec8170c2f87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Create a dataframe from the dictionary\n",
    "# # df = pd.DataFrame.from_dict(result)\n",
    "# df = pd.DataFrame.from_dict({(i,j,k,l): result[i][j][k][l] \n",
    "#                            for i in result.keys() \n",
    "#                            for j in result[i].keys()\n",
    "#                            for k in result[i][j].keys()\n",
    "#                            for l in result[i][j][k].keys()},\n",
    "#                        orient='index')\n",
    "# \"\"\"\n",
    "# This code creates a dictionary comprehension that iterates over four levels of nested dictionaries (result[i][j][k][l]) and maps the values of the innermost level to a tuple of keys (i,j,k,l) using a dictionary key. The dictionary key is created by concatenating the tuple of keys with a comma, creating a tuple of tuples.\n",
    "\n",
    "# The pd.DataFrame.from_dict() method is then called on this dictionary to create a DataFrame df. The orient parameter is set to 'index' to use the dictionary keys as the index of the DataFrame.\n",
    "\n",
    "# Essentially, this code flattens the nested dictionary structure into a Pandas DataFrame where each row corresponds to a unique combination of the dictionary keys (i,j,k,l) and the corresponding value at the innermost level.\n",
    "# \"\"\"\n",
    "\n",
    "# df.reset_index(inplace=True)\n",
    "# df = df.pivot_table(index=['level_0', 'level_1', 'level_2'], columns='level_3', values='acc')\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d7210c-f150-4cf8-b002-e287e39c3574",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # calculate max, avg, min\n",
    "# df['max'] = df.max(axis=1)\n",
    "# df['mean'] = df.mean(axis=1)\n",
    "# df['min'] = df.min(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328cbeaf-9ced-413d-80bb-3a9ab577b738",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
