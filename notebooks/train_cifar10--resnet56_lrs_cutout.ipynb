{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb41af0-d2d4-4c9c-9e7d-ab0d1db94596",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://github.com/shoji9x9/CIFAR-10-By-small-ResNet/blob/master/ResNet-for-CIFAR-10-with-Keras.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fd7612-8606-44ff-9fc3-aa4c8e848cc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import git\n",
    "import pathlib\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "\n",
    "PROJ_ROOT_PATH = pathlib.Path(git.Repo('.', search_parent_directories=True).working_tree_dir)\n",
    "PROJ_ROOT =  str(PROJ_ROOT_PATH)\n",
    "if PROJ_ROOT not in sys.path:\n",
    "    sys.path.append(PROJ_ROOT)\n",
    "\n",
    "from libs.constants import MODELS_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5127b421-8963-4d68-bd72-293be41d7fd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Limit GPU growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fec3701-0818-4940-adc5-03aced736861",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import libs.model_archs\n",
    "import libs.utils\n",
    "from libs.seeds import load_model_seeds\n",
    "model_seeds = load_model_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f08e42-236b-4329-92ff-92e811be298c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define dataset and model architecture\n",
    "dataset = \"cifar10\"\n",
    "# Select ResNet Version\n",
    "resnet_version = 1\n",
    "model_arch = \"resnetA\" + str(resnet_version)\n",
    "\n",
    "# set training hyperparameters\n",
    "batch_size = 128\n",
    "n_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429bb6cd-559b-4edf-8ce6-b51721b7f5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "class CustomImageDataGenerator(ImageDataGenerator):\n",
    "    def __init__(self, cutout_mask_size = 0, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.cutout_mask_size = cutout_mask_size\n",
    "        \n",
    "    def cutout(self, x, y):\n",
    "        return np.array(list(map(self._cutout, x))), y\n",
    "    \n",
    "    def _cutout(self, image_origin):\n",
    "        # 最後に使うfill()は元の画像を書き換えるので、コピーしておく\n",
    "        image = np.copy(image_origin)\n",
    "        mask_value = image.mean()\n",
    "\n",
    "        h, w, _ = image.shape\n",
    "        # マスクをかける場所のtop, leftをランダムに決める\n",
    "        # はみ出すことを許すので、0以上ではなく負の値もとる(最大mask_size // 2はみ出す)\n",
    "        top = np.random.randint(0 - self.cutout_mask_size // 2, h - self.cutout_mask_size)\n",
    "        left = np.random.randint(0 - self.cutout_mask_size // 2, w - self.cutout_mask_size)\n",
    "        bottom = top + self.cutout_mask_size\n",
    "        right = left + self.cutout_mask_size\n",
    "\n",
    "        # はみ出した場合の処理\n",
    "        if top < 0:\n",
    "            top = 0\n",
    "        if left < 0:\n",
    "            left = 0\n",
    "\n",
    "        # マスク部分の画素値を平均値で埋める\n",
    "        image[top:bottom, left:right, :].fill(mask_value)\n",
    "        return image\n",
    "    \n",
    "    def flow(self, *args, **kwargs):\n",
    "        batches = super().flow(*args, **kwargs)\n",
    "        \n",
    "        # 拡張処理\n",
    "        while True:\n",
    "            batch_x, batch_y = next(batches)\n",
    "            \n",
    "            if self.cutout_mask_size > 0:\n",
    "                result = self.cutout(batch_x, batch_y)\n",
    "                batch_x, batch_y = result                        \n",
    "                \n",
    "            yield (batch_x, batch_y)     \n",
    "\n",
    "datagen_parameters = {\"horizontal_flip\": True, \"width_shift_range\": 0.1, \"height_shift_range\": 0.1, \"cutout_mask_size\": 16}\n",
    "datagen = CustomImageDataGenerator(**datagen_parameters)\n",
    "datagen_for_test = ImageDataGenerator()\n",
    "# ZCA whiteningなどを行う場合が以下の実行が必要\n",
    "# datagen.fit(train_x)\n",
    "# datagen_for_test.fit(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c166d223-419d-48ac-8bed-b6933a4bb475",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# global seed\n",
    "seed = model_seeds[0]\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# prepare data\n",
    "# dataset_loader = getattr(libs.utils, 'prepare_'+dataset)\n",
    "# to_categorical=False\n",
    "# (x_train, y_train), (x_test, y_test) = dataset_loader(to_categorical)\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "dataset_test = (x_test, y_test) \n",
    "dataset_train = (x_train, y_train)\n",
    "\n",
    "x_train = dataset_train[0] / 255\n",
    "y_train = dataset_train[1].squeeze()\n",
    "x_test = dataset_test[0] / 255\n",
    "y_test = dataset_test[1].squeeze()\n",
    "\n",
    "number_train = x_train.shape[0]\n",
    "number_test = x_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e786c9dc-5600-4c9b-8605-6894eef91bda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "class LearningController(Callback):\n",
    "    def __init__(self, num_epoch=0, learn_minute=0):\n",
    "        self.num_epoch = num_epoch\n",
    "        self.learn_second = learn_minute * 60\n",
    "        if self.learn_second > 0:\n",
    "            print(\"Learning rate is controled by time.\")\n",
    "        elif self.num_epoch > 0:\n",
    "            print(\"Learning rate is controled by epoch.\")\n",
    "        \n",
    "    def on_train_begin(self, logs=None):\n",
    "        if self.learn_second > 0:\n",
    "            self.start_time = time.time()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self.learn_second > 0:\n",
    "            current_time = time.time()\n",
    "            if current_time - self.start_time > self.learn_second:\n",
    "                self.model.stop_training = True\n",
    "                print(\"Time is up.\")\n",
    "                return\n",
    "\n",
    "            if current_time - self.start_time > self.learn_second / 2:\n",
    "                self.model.optimizer.lr = lr * 0.1            \n",
    "            if current_time - self.start_time > self.learn_second * 3 / 4:\n",
    "                self.model.optimizer.lr = lr * 0.01\n",
    "                \n",
    "        elif self.num_epoch > 0:\n",
    "            if epoch > self.num_epoch / 2:\n",
    "                self.model.optimizer.lr = lr * 0.1            \n",
    "            if epoch > self.num_epoch * 3 / 4:\n",
    "                self.model.optimizer.lr = lr * 0.01\n",
    "                    \n",
    "        print('\\nlr:%.2e' % self.model.optimizer.lr.value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f5b823-46bf-4ada-9ea0-6864a8a1284d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "from tensorflow.keras.layers import Conv2D, Dense, BatchNormalization, Activation, MaxPool2D, GlobalAveragePooling2D, Add, Input, Flatten\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "\n",
    "input_shape = (x_train.shape[1], x_train.shape[2], x_train.shape[3])\n",
    "n_classes = y_train.shape\n",
    "\n",
    "# n_channels = x_train.shape[3] # no. of channels (?)\n",
    "# # Computed depth of model\n",
    "# if resnet_version == 1:\n",
    "# \tdepth = n_channels * 6 + 2\n",
    "# elif resnet_version == 2:\n",
    "# \tdepth = n_channels * 9 + 2\n",
    "\n",
    "# model_generator = getattr(libs.model_archs, model_arch)\n",
    "# model = model_generator(input_shape, depth, n_classes)\n",
    "\n",
    "n = 9 # depth should be 9*6 + 2 = 56 layers\n",
    "channels = [16, 32, 64]\n",
    "\n",
    "inputs = Input(shape=input_shape)\n",
    "x = Conv2D(channels[0], \n",
    "           kernel_size=(3, 3), \n",
    "           padding=\"same\", \n",
    "           kernel_initializer=\"he_normal\", \n",
    "           kernel_regularizer=l2(1e-4))(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(tf.nn.relu)(x)\n",
    "\n",
    "for c in channels:\n",
    "    for i in range(n):\n",
    "        subsampling = i == 0 and c > 16\n",
    "        strides = (2, 2) if subsampling else (1, 1)\n",
    "        y = Conv2D(c, \n",
    "                   kernel_size=(3, 3), \n",
    "                   padding=\"same\", \n",
    "                   strides=strides, \n",
    "                   kernel_initializer=\"he_normal\", \n",
    "                   kernel_regularizer=l2(1e-4))(x)\n",
    "        y = BatchNormalization()(y)\n",
    "        y = Activation(tf.nn.relu)(y)\n",
    "        y = Conv2D(c, \n",
    "                   kernel_size=(3, 3), \n",
    "                   padding=\"same\", \n",
    "                   kernel_initializer=\"he_normal\", \n",
    "                   kernel_regularizer=l2(1e-4))(y)\n",
    "        y = BatchNormalization()(y)\n",
    "        if subsampling:\n",
    "            x = Conv2D(c, \n",
    "                       kernel_size=(1, 1), \n",
    "                       strides=(2, 2), \n",
    "                       padding=\"same\", \n",
    "                       kernel_initializer=\"he_normal\", \n",
    "                       kernel_regularizer=l2(1e-4))(x)\n",
    "        x = Add()([x, y])\n",
    "        x = Activation(tf.nn.relu)(x)\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Flatten()(x)\n",
    "outputs = Dense(10, \n",
    "                activation=tf.nn.softmax, \n",
    "                kernel_initializer=\"he_normal\")(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model._name = \"resnet_lrs_cutout\" + str(6 * n + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05a8e80-363e-400b-b8e7-6f9d0e9eb4f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "# checkpoint = ModelCheckpoint(filepath = \"ResNet-for-CIFAR-10-with-Keras.h5\", \n",
    "#                              monitor=\"val_loss\", \n",
    "#                              verbose=1, \n",
    "#                              save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72459af0-69f4-43c9-a3f3-7c8670b00359",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compile model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "# model.compile(loss ='categorical_crossentropy',\n",
    "#               optimizer ='adam',\n",
    "#               metrics =['accuracy'])\n",
    "lr = 0.1\n",
    "optimizer = SGD(learning_rate=lr, momentum=0.9)\n",
    "model.compile(optimizer=optimizer, \n",
    "              loss=\"sparse_categorical_crossentropy\", \n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "learning_controller = LearningController(n_epochs)\n",
    "callbacks = [learning_controller]\n",
    "# train model\n",
    "model.fit(datagen.flow(x_train, \n",
    "                         y_train, \n",
    "                         batch_size=batch_size), \n",
    "          epochs=n_epochs,\n",
    "          steps_per_epoch=number_train//batch_size,\n",
    "          validation_data=datagen_for_test.flow(x_test, \n",
    "                                                  y_test, \n",
    "                                                  batch_size=batch_size),\n",
    "          validation_steps=number_test//batch_size,\n",
    "          validation_split=0.2,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9b8fda-5395-4334-8e95-dd7029b558d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "score = model.evaluate(x_test, \n",
    "                       y_test, \n",
    "                       batch_size=batch_size)\n",
    "\n",
    "print(\"Original Accuracy: \",score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4160444-eaa9-47a9-831d-db3e89cd0e6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "model_type = dataset + \"--\" + model_arch\n",
    "model_instance = model_type + \"-\" + str(seed)\n",
    "model_filename = model_instance + \".h5\"\n",
    "model_subdir = pathlib.Path(MODELS_FOLDER / model.name)\n",
    "pathlib.Path(model_subdir).mkdir(parents=True, exist_ok=True)\n",
    "model_file = str(pathlib.Path(model_subdir/ model_filename))\n",
    "model.save(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11d853e-0eb6-432c-b767-473adc0dad2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951abcd3-78dc-4b84-ac86-50c46b3cf419",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
