{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cb41af0-d2d4-4c9c-9e7d-ab0d1db94596",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://github.com/shoji9x9/CIFAR-10-By-small-ResNet/blob/master/ResNet-for-CIFAR-10-with-Keras.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17fd7612-8606-44ff-9fc3-aa4c8e848cc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import git\n",
    "import pathlib\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "\n",
    "PROJ_ROOT_PATH = pathlib.Path(git.Repo('.', search_parent_directories=True).working_tree_dir)\n",
    "PROJ_ROOT =  str(PROJ_ROOT_PATH)\n",
    "if PROJ_ROOT not in sys.path:\n",
    "    sys.path.append(PROJ_ROOT)\n",
    "\n",
    "from libs.constants import MODELS_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5127b421-8963-4d68-bd72-293be41d7fd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Limit GPU growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fec3701-0818-4940-adc5-03aced736861",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import libs.model_archs\n",
    "import libs.utils\n",
    "from libs.seeds import load_model_seeds\n",
    "model_seeds = load_model_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8f08e42-236b-4329-92ff-92e811be298c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define dataset and model architecture\n",
    "dataset = \"cifar10\"\n",
    "# Select ResNet Version\n",
    "resnet_version = 1\n",
    "model_arch = \"resnetA\" + str(resnet_version)\n",
    "\n",
    "# set training hyperparameters\n",
    "batch_size = 128\n",
    "n_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c166d223-419d-48ac-8bed-b6933a4bb475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global seed\n",
    "seed = model_seeds[0]\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# prepare data\n",
    "dataset_loader = getattr(libs.utils, 'prepare_'+dataset)\n",
    "to_categorical=False\n",
    "(x_train, y_train), (x_test, y_test) = dataset_loader(to_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96f5b823-46bf-4ada-9ea0-6864a8a1284d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "from tensorflow.keras.layers import Conv2D, Dense, BatchNormalization, Activation, MaxPool2D, GlobalAveragePooling2D, Add, Input, Flatten\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "\n",
    "input_shape = (x_train.shape[1], x_train.shape[2], x_train.shape[3])\n",
    "n_classes = y_train.shape[1]\n",
    "\n",
    "# n_channels = x_train.shape[3] # no. of channels (?)\n",
    "# # Computed depth of model\n",
    "# if resnet_version == 1:\n",
    "# \tdepth = n_channels * 6 + 2\n",
    "# elif resnet_version == 2:\n",
    "# \tdepth = n_channels * 9 + 2\n",
    "\n",
    "# model_generator = getattr(libs.model_archs, model_arch)\n",
    "# model = model_generator(input_shape, depth, n_classes)\n",
    "\n",
    "# https://github.com/shoji9x9/CIFAR-10-By-small-ResNet/blob/master/ResNet-for-CIFAR-10-with-Keras.ipynb\n",
    "n = 9 # 56 layers\n",
    "channels = [16, 32, 64]\n",
    "\n",
    "inputs = Input(shape=input_shape)\n",
    "x = Conv2D(channels[0], \n",
    "           kernel_size=(3, 3), \n",
    "           padding=\"same\", \n",
    "           kernel_initializer=\"he_normal\", \n",
    "           kernel_regularizer=l2(1e-4))(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(tf.nn.relu)(x)\n",
    "\n",
    "for c in channels:\n",
    "    for i in range(n):\n",
    "        subsampling = i == 0 and c > 16\n",
    "        strides = (2, 2) if subsampling else (1, 1)\n",
    "        y = Conv2D(c, \n",
    "                   kernel_size=(3, 3), \n",
    "                   padding=\"same\", \n",
    "                   strides=strides, \n",
    "                   kernel_initializer=\"he_normal\", \n",
    "                   kernel_regularizer=l2(1e-4))(x)\n",
    "        y = BatchNormalization()(y)\n",
    "        y = Activation(tf.nn.relu)(y)\n",
    "        y = Conv2D(c, \n",
    "                   kernel_size=(3, 3), \n",
    "                   padding=\"same\", \n",
    "                   kernel_initializer=\"he_normal\", \n",
    "                   kernel_regularizer=l2(1e-4))(y)\n",
    "        y = BatchNormalization()(y)\n",
    "        if subsampling:\n",
    "            x = Conv2D(c, \n",
    "                       kernel_size=(1, 1), \n",
    "                       strides=(2, 2), \n",
    "                       padding=\"same\", \n",
    "                       kernel_initializer=\"he_normal\", \n",
    "                       kernel_regularizer=l2(1e-4))(x)\n",
    "        x = Add()([x, y])\n",
    "        x = Activation(tf.nn.relu)(x)\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Flatten()(x)\n",
    "outputs = Dense(10, \n",
    "                activation=tf.nn.softmax, \n",
    "                kernel_initializer=\"he_normal\")(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model._name = \"resnet\" + str(6 * n + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72459af0-69f4-43c9-a3f3-7c8670b00359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "313/313 [==============================] - 69s 137ms/step - loss: 3.1882 - accuracy: 0.1886 - val_loss: 2.8692 - val_accuracy: 0.2195\n",
      "Epoch 2/200\n",
      "313/313 [==============================] - 37s 118ms/step - loss: 2.5589 - accuracy: 0.3111 - val_loss: 2.6552 - val_accuracy: 0.2717\n",
      "Epoch 3/200\n",
      "313/313 [==============================] - 37s 119ms/step - loss: 2.2001 - accuracy: 0.4236 - val_loss: 2.2438 - val_accuracy: 0.4127\n",
      "Epoch 4/200\n",
      "313/313 [==============================] - 38s 123ms/step - loss: 1.9477 - accuracy: 0.4992 - val_loss: 1.9292 - val_accuracy: 0.4909\n",
      "Epoch 5/200\n",
      "313/313 [==============================] - 37s 119ms/step - loss: 1.7551 - accuracy: 0.5552 - val_loss: 1.9281 - val_accuracy: 0.4827\n",
      "Epoch 6/200\n",
      "313/313 [==============================] - 37s 117ms/step - loss: 1.5952 - accuracy: 0.6012 - val_loss: 2.0012 - val_accuracy: 0.4629\n",
      "Epoch 7/200\n",
      "313/313 [==============================] - 39s 125ms/step - loss: 1.4398 - accuracy: 0.6439 - val_loss: 1.6335 - val_accuracy: 0.5895\n",
      "Epoch 8/200\n",
      "313/313 [==============================] - 38s 120ms/step - loss: 1.3124 - accuracy: 0.6824 - val_loss: 1.4111 - val_accuracy: 0.6516\n",
      "Epoch 9/200\n",
      "313/313 [==============================] - 36s 114ms/step - loss: 1.1894 - accuracy: 0.7184 - val_loss: 1.7553 - val_accuracy: 0.5813\n",
      "Epoch 10/200\n",
      "313/313 [==============================] - 39s 124ms/step - loss: 1.0910 - accuracy: 0.7467 - val_loss: 1.8297 - val_accuracy: 0.5609\n",
      "Epoch 11/200\n",
      "313/313 [==============================] - 38s 122ms/step - loss: 1.0113 - accuracy: 0.7690 - val_loss: 1.6074 - val_accuracy: 0.6196\n",
      "Epoch 12/200\n",
      "313/313 [==============================] - 35s 113ms/step - loss: 0.9470 - accuracy: 0.7905 - val_loss: 1.2965 - val_accuracy: 0.6880\n",
      "Epoch 13/200\n",
      "313/313 [==============================] - 39s 125ms/step - loss: 0.8874 - accuracy: 0.8051 - val_loss: 1.5181 - val_accuracy: 0.6271\n",
      "Epoch 14/200\n",
      "313/313 [==============================] - 39s 124ms/step - loss: 0.8392 - accuracy: 0.8207 - val_loss: 1.4366 - val_accuracy: 0.6633\n",
      "Epoch 15/200\n",
      "313/313 [==============================] - 35s 111ms/step - loss: 0.8000 - accuracy: 0.8340 - val_loss: 1.4346 - val_accuracy: 0.6568\n",
      "Epoch 16/200\n",
      "313/313 [==============================] - 39s 124ms/step - loss: 0.7626 - accuracy: 0.8457 - val_loss: 1.3235 - val_accuracy: 0.7103\n",
      "Epoch 17/200\n",
      "313/313 [==============================] - 39s 123ms/step - loss: 0.7337 - accuracy: 0.8579 - val_loss: 1.1423 - val_accuracy: 0.7359\n",
      "Epoch 18/200\n",
      "313/313 [==============================] - 38s 122ms/step - loss: 0.7103 - accuracy: 0.8644 - val_loss: 1.5483 - val_accuracy: 0.6495\n",
      "Epoch 19/200\n",
      "313/313 [==============================] - 38s 121ms/step - loss: 0.6893 - accuracy: 0.8736 - val_loss: 1.6383 - val_accuracy: 0.6488\n",
      "Epoch 20/200\n",
      "313/313 [==============================] - 36s 115ms/step - loss: 0.6700 - accuracy: 0.8804 - val_loss: 1.7277 - val_accuracy: 0.6534\n",
      "Epoch 21/200\n",
      "313/313 [==============================] - 39s 124ms/step - loss: 0.6510 - accuracy: 0.8919 - val_loss: 1.7597 - val_accuracy: 0.6323\n",
      "Epoch 22/200\n",
      "313/313 [==============================] - 39s 125ms/step - loss: 0.6417 - accuracy: 0.8953 - val_loss: 1.4679 - val_accuracy: 0.7033\n",
      "Epoch 23/200\n",
      "313/313 [==============================] - 39s 125ms/step - loss: 0.6377 - accuracy: 0.8985 - val_loss: 1.9606 - val_accuracy: 0.6403\n",
      "Epoch 24/200\n",
      "313/313 [==============================] - 37s 119ms/step - loss: 0.6166 - accuracy: 0.9068 - val_loss: 1.2125 - val_accuracy: 0.7562\n",
      "Epoch 25/200\n",
      "313/313 [==============================] - 37s 117ms/step - loss: 0.6190 - accuracy: 0.9097 - val_loss: 1.5227 - val_accuracy: 0.6939\n",
      "Epoch 26/200\n",
      "313/313 [==============================] - 39s 123ms/step - loss: 0.5963 - accuracy: 0.9184 - val_loss: 1.4605 - val_accuracy: 0.7367\n",
      "Epoch 27/200\n",
      "313/313 [==============================] - 39s 126ms/step - loss: 0.5915 - accuracy: 0.9215 - val_loss: 2.1948 - val_accuracy: 0.6074\n",
      "Epoch 28/200\n",
      "313/313 [==============================] - 39s 124ms/step - loss: 0.6148 - accuracy: 0.9149 - val_loss: 1.4662 - val_accuracy: 0.7128\n",
      "Epoch 29/200\n",
      "313/313 [==============================] - 36s 114ms/step - loss: 0.5866 - accuracy: 0.9281 - val_loss: 1.4928 - val_accuracy: 0.7173\n",
      "Epoch 30/200\n",
      "313/313 [==============================] - 38s 123ms/step - loss: 0.6008 - accuracy: 0.9217 - val_loss: 1.3868 - val_accuracy: 0.7403\n",
      "Epoch 31/200\n",
      "313/313 [==============================] - 39s 123ms/step - loss: 0.5798 - accuracy: 0.9311 - val_loss: 1.9110 - val_accuracy: 0.6732\n",
      "Epoch 32/200\n",
      "313/313 [==============================] - 39s 124ms/step - loss: 0.5894 - accuracy: 0.9293 - val_loss: 1.7939 - val_accuracy: 0.6599\n",
      "Epoch 33/200\n",
      "313/313 [==============================] - 38s 122ms/step - loss: 0.5799 - accuracy: 0.9334 - val_loss: 1.4420 - val_accuracy: 0.7434\n",
      "Epoch 34/200\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.5785 - accuracy: 0.9347 - val_loss: 1.6280 - val_accuracy: 0.6932\n",
      "Epoch 35/200\n",
      "313/313 [==============================] - 39s 125ms/step - loss: 0.5724 - accuracy: 0.9364 - val_loss: 1.9052 - val_accuracy: 0.6937\n",
      "Epoch 36/200\n",
      "313/313 [==============================] - 39s 125ms/step - loss: 0.5777 - accuracy: 0.9358 - val_loss: 1.7856 - val_accuracy: 0.6926\n",
      "Epoch 37/200\n",
      "313/313 [==============================] - 39s 125ms/step - loss: 0.5754 - accuracy: 0.9387 - val_loss: 1.8350 - val_accuracy: 0.7021\n",
      "Epoch 38/200\n",
      "313/313 [==============================] - 39s 123ms/step - loss: 0.5565 - accuracy: 0.9459 - val_loss: 1.4566 - val_accuracy: 0.7184\n",
      "Epoch 39/200\n",
      "313/313 [==============================] - 34s 110ms/step - loss: 0.5665 - accuracy: 0.9406 - val_loss: 2.2699 - val_accuracy: 0.6398\n",
      "Epoch 40/200\n",
      "313/313 [==============================] - 38s 122ms/step - loss: 0.5665 - accuracy: 0.9419 - val_loss: 2.0216 - val_accuracy: 0.6762\n",
      "Epoch 41/200\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.5565 - accuracy: 0.9449 - val_loss: 1.7194 - val_accuracy: 0.7109\n",
      "Epoch 42/200\n",
      "313/313 [==============================] - 38s 120ms/step - loss: 0.5608 - accuracy: 0.9441 - val_loss: 1.6811 - val_accuracy: 0.7154\n",
      "Epoch 43/200\n",
      "313/313 [==============================] - 36s 115ms/step - loss: 0.5585 - accuracy: 0.9444 - val_loss: 1.5422 - val_accuracy: 0.7204\n",
      "Epoch 44/200\n",
      "313/313 [==============================] - 37s 119ms/step - loss: 0.5598 - accuracy: 0.9439 - val_loss: 1.8498 - val_accuracy: 0.7061\n",
      "Epoch 45/200\n",
      "313/313 [==============================] - 36s 115ms/step - loss: 0.5538 - accuracy: 0.9470 - val_loss: 1.5334 - val_accuracy: 0.7323\n",
      "Epoch 46/200\n",
      "313/313 [==============================] - 37s 117ms/step - loss: 0.5548 - accuracy: 0.9478 - val_loss: 1.5003 - val_accuracy: 0.7477\n",
      "Epoch 47/200\n",
      "313/313 [==============================] - 36s 116ms/step - loss: 0.5538 - accuracy: 0.9463 - val_loss: 2.1522 - val_accuracy: 0.6595\n",
      "Epoch 48/200\n",
      "313/313 [==============================] - 36s 114ms/step - loss: 0.5575 - accuracy: 0.9460 - val_loss: 1.5511 - val_accuracy: 0.7390\n",
      "Epoch 49/200\n",
      "313/313 [==============================] - 37s 120ms/step - loss: 0.5595 - accuracy: 0.9456 - val_loss: 1.6111 - val_accuracy: 0.7351\n",
      "Epoch 50/200\n",
      "313/313 [==============================] - 36s 115ms/step - loss: 0.5567 - accuracy: 0.9473 - val_loss: 1.4789 - val_accuracy: 0.7379\n",
      "Epoch 51/200\n",
      "313/313 [==============================] - 38s 120ms/step - loss: 0.5418 - accuracy: 0.9518 - val_loss: 2.0528 - val_accuracy: 0.6914\n",
      "Epoch 52/200\n",
      "313/313 [==============================] - 35s 113ms/step - loss: 0.5637 - accuracy: 0.9435 - val_loss: 1.6500 - val_accuracy: 0.6988\n",
      "Epoch 53/200\n",
      "313/313 [==============================] - 38s 122ms/step - loss: 0.5313 - accuracy: 0.9566 - val_loss: 1.7691 - val_accuracy: 0.7100\n",
      "Epoch 54/200\n",
      "313/313 [==============================] - 36s 114ms/step - loss: 0.5374 - accuracy: 0.9528 - val_loss: 1.8066 - val_accuracy: 0.7105\n",
      "Epoch 55/200\n",
      "313/313 [==============================] - 38s 122ms/step - loss: 0.5464 - accuracy: 0.9507 - val_loss: 1.4981 - val_accuracy: 0.7408\n",
      "Epoch 56/200\n",
      "313/313 [==============================] - 36s 114ms/step - loss: 0.5538 - accuracy: 0.9477 - val_loss: 1.6163 - val_accuracy: 0.7154\n",
      "Epoch 57/200\n",
      "313/313 [==============================] - 39s 123ms/step - loss: 0.5446 - accuracy: 0.9515 - val_loss: 1.4484 - val_accuracy: 0.7542\n",
      "Epoch 58/200\n",
      "313/313 [==============================] - 34s 110ms/step - loss: 0.5259 - accuracy: 0.9564 - val_loss: 1.3845 - val_accuracy: 0.7647\n",
      "Epoch 59/200\n",
      "313/313 [==============================] - 38s 122ms/step - loss: 0.5370 - accuracy: 0.9523 - val_loss: 1.4412 - val_accuracy: 0.7549\n",
      "Epoch 60/200\n",
      "313/313 [==============================] - 35s 111ms/step - loss: 0.5459 - accuracy: 0.9514 - val_loss: 1.7672 - val_accuracy: 0.7130\n",
      "Epoch 61/200\n",
      "313/313 [==============================] - 38s 122ms/step - loss: 0.5236 - accuracy: 0.9557 - val_loss: 1.8068 - val_accuracy: 0.7039\n",
      "Epoch 62/200\n",
      "313/313 [==============================] - 36s 114ms/step - loss: 0.5410 - accuracy: 0.9511 - val_loss: 1.5241 - val_accuracy: 0.7389\n",
      "Epoch 63/200\n",
      "313/313 [==============================] - 38s 123ms/step - loss: 0.5219 - accuracy: 0.9584 - val_loss: 1.5845 - val_accuracy: 0.7068\n",
      "Epoch 64/200\n",
      "313/313 [==============================] - 36s 115ms/step - loss: 0.5317 - accuracy: 0.9531 - val_loss: 1.5460 - val_accuracy: 0.7417\n",
      "Epoch 65/200\n",
      "313/313 [==============================] - 37s 119ms/step - loss: 0.5229 - accuracy: 0.9556 - val_loss: 1.4843 - val_accuracy: 0.7447\n",
      "Epoch 66/200\n",
      "313/313 [==============================] - 37s 118ms/step - loss: 0.5349 - accuracy: 0.9533 - val_loss: 1.3826 - val_accuracy: 0.7482\n",
      "Epoch 67/200\n",
      "313/313 [==============================] - 36s 115ms/step - loss: 0.5244 - accuracy: 0.9564 - val_loss: 1.7121 - val_accuracy: 0.7443\n",
      "Epoch 68/200\n",
      "313/313 [==============================] - 38s 122ms/step - loss: 0.5150 - accuracy: 0.9592 - val_loss: 2.0965 - val_accuracy: 0.6809\n",
      "Epoch 69/200\n",
      "313/313 [==============================] - 35s 111ms/step - loss: 0.5347 - accuracy: 0.9525 - val_loss: 1.4283 - val_accuracy: 0.7556\n",
      "Epoch 70/200\n",
      "313/313 [==============================] - 38s 122ms/step - loss: 0.5140 - accuracy: 0.9599 - val_loss: 1.7942 - val_accuracy: 0.7037\n",
      "Epoch 71/200\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.5141 - accuracy: 0.9594 - val_loss: 1.7029 - val_accuracy: 0.7247\n",
      "Epoch 72/200\n",
      "313/313 [==============================] - 38s 120ms/step - loss: 0.5294 - accuracy: 0.9538 - val_loss: 1.8389 - val_accuracy: 0.6846\n",
      "Epoch 73/200\n",
      "313/313 [==============================] - 36s 115ms/step - loss: 0.5215 - accuracy: 0.9574 - val_loss: 1.3863 - val_accuracy: 0.7652\n",
      "Epoch 74/200\n",
      "313/313 [==============================] - 37s 119ms/step - loss: 0.5030 - accuracy: 0.9618 - val_loss: 2.1727 - val_accuracy: 0.6405\n",
      "Epoch 75/200\n",
      "313/313 [==============================] - 37s 120ms/step - loss: 0.5131 - accuracy: 0.9585 - val_loss: 1.5462 - val_accuracy: 0.7453\n",
      "Epoch 76/200\n",
      "313/313 [==============================] - 36s 114ms/step - loss: 0.5154 - accuracy: 0.9573 - val_loss: 1.5481 - val_accuracy: 0.7572\n",
      "Epoch 77/200\n",
      "313/313 [==============================] - 38s 121ms/step - loss: 0.5204 - accuracy: 0.9556 - val_loss: 1.6182 - val_accuracy: 0.7243\n",
      "Epoch 78/200\n",
      "313/313 [==============================] - 34s 110ms/step - loss: 0.5233 - accuracy: 0.9558 - val_loss: 1.9412 - val_accuracy: 0.6849\n",
      "Epoch 79/200\n",
      "313/313 [==============================] - 38s 122ms/step - loss: 0.5229 - accuracy: 0.9567 - val_loss: 1.4552 - val_accuracy: 0.7531\n",
      "Epoch 80/200\n",
      "313/313 [==============================] - 36s 115ms/step - loss: 0.5100 - accuracy: 0.9597 - val_loss: 1.5844 - val_accuracy: 0.7331\n",
      "Epoch 81/200\n",
      "313/313 [==============================] - 37s 118ms/step - loss: 0.5194 - accuracy: 0.9573 - val_loss: 1.8044 - val_accuracy: 0.7215\n",
      "Epoch 82/200\n",
      "313/313 [==============================] - 38s 121ms/step - loss: 0.4970 - accuracy: 0.9638 - val_loss: 2.0692 - val_accuracy: 0.6779\n",
      "Epoch 83/200\n",
      "313/313 [==============================] - 35s 111ms/step - loss: 0.5209 - accuracy: 0.9560 - val_loss: 1.9618 - val_accuracy: 0.6583\n",
      "Epoch 84/200\n",
      "313/313 [==============================] - 38s 122ms/step - loss: 0.5042 - accuracy: 0.9607 - val_loss: 1.6691 - val_accuracy: 0.7306\n",
      "Epoch 85/200\n",
      "313/313 [==============================] - 37s 118ms/step - loss: 0.5051 - accuracy: 0.9599 - val_loss: 2.2497 - val_accuracy: 0.6652\n",
      "Epoch 86/200\n",
      "313/313 [==============================] - 36s 116ms/step - loss: 0.5082 - accuracy: 0.9602 - val_loss: 1.3452 - val_accuracy: 0.7678\n",
      "Epoch 87/200\n",
      "313/313 [==============================] - 38s 121ms/step - loss: 0.5077 - accuracy: 0.9582 - val_loss: 1.5138 - val_accuracy: 0.7511\n",
      "Epoch 88/200\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.5019 - accuracy: 0.9608 - val_loss: 1.4815 - val_accuracy: 0.7658\n",
      "Epoch 89/200\n",
      "313/313 [==============================] - 38s 122ms/step - loss: 0.5075 - accuracy: 0.9595 - val_loss: 1.8390 - val_accuracy: 0.7142\n",
      "Epoch 90/200\n",
      "313/313 [==============================] - 38s 120ms/step - loss: 0.5056 - accuracy: 0.9596 - val_loss: 1.4757 - val_accuracy: 0.7352\n",
      "Epoch 91/200\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.4879 - accuracy: 0.9650 - val_loss: 1.4188 - val_accuracy: 0.7689\n",
      "Epoch 92/200\n",
      "313/313 [==============================] - 38s 123ms/step - loss: 0.5096 - accuracy: 0.9585 - val_loss: 1.6340 - val_accuracy: 0.7394\n",
      "Epoch 93/200\n",
      "313/313 [==============================] - 38s 122ms/step - loss: 0.4902 - accuracy: 0.9641 - val_loss: 1.4678 - val_accuracy: 0.7624\n",
      "Epoch 94/200\n",
      "313/313 [==============================] - 35s 113ms/step - loss: 0.5007 - accuracy: 0.9596 - val_loss: 1.4554 - val_accuracy: 0.7509\n",
      "Epoch 95/200\n",
      "313/313 [==============================] - 39s 124ms/step - loss: 0.5016 - accuracy: 0.9602 - val_loss: 1.6283 - val_accuracy: 0.7095\n",
      "Epoch 96/200\n",
      "313/313 [==============================] - 37s 118ms/step - loss: 0.5035 - accuracy: 0.9589 - val_loss: 1.9893 - val_accuracy: 0.7035\n",
      "Epoch 97/200\n",
      "313/313 [==============================] - 38s 120ms/step - loss: 0.5057 - accuracy: 0.9595 - val_loss: 1.4929 - val_accuracy: 0.7422\n",
      "Epoch 98/200\n",
      "313/313 [==============================] - 39s 124ms/step - loss: 0.5100 - accuracy: 0.9579 - val_loss: 1.3646 - val_accuracy: 0.7799\n",
      "Epoch 99/200\n",
      "313/313 [==============================] - 38s 122ms/step - loss: 0.4964 - accuracy: 0.9629 - val_loss: 1.7984 - val_accuracy: 0.7321\n",
      "Epoch 100/200\n",
      "313/313 [==============================] - 35s 113ms/step - loss: 0.5050 - accuracy: 0.9603 - val_loss: 1.7684 - val_accuracy: 0.7251\n",
      "Epoch 101/200\n",
      "313/313 [==============================] - 39s 124ms/step - loss: 0.4963 - accuracy: 0.9629 - val_loss: 1.3661 - val_accuracy: 0.7710\n",
      "Epoch 102/200\n",
      "313/313 [==============================] - 39s 124ms/step - loss: 0.4837 - accuracy: 0.9658 - val_loss: 1.3560 - val_accuracy: 0.7732\n",
      "Epoch 103/200\n",
      "313/313 [==============================] - 38s 123ms/step - loss: 0.4838 - accuracy: 0.9650 - val_loss: 1.3829 - val_accuracy: 0.7645\n",
      "Epoch 104/200\n",
      "313/313 [==============================] - 36s 114ms/step - loss: 0.4955 - accuracy: 0.9616 - val_loss: 1.5557 - val_accuracy: 0.7482\n",
      "Epoch 105/200\n",
      "313/313 [==============================] - 39s 123ms/step - loss: 0.5027 - accuracy: 0.9594 - val_loss: 1.5003 - val_accuracy: 0.7536\n",
      "Epoch 106/200\n",
      "313/313 [==============================] - 38s 122ms/step - loss: 0.4788 - accuracy: 0.9674 - val_loss: 2.3031 - val_accuracy: 0.6237\n",
      "Epoch 107/200\n",
      "313/313 [==============================] - 38s 120ms/step - loss: 0.4862 - accuracy: 0.9643 - val_loss: 1.7051 - val_accuracy: 0.7311\n",
      "Epoch 108/200\n",
      "313/313 [==============================] - 36s 114ms/step - loss: 0.4985 - accuracy: 0.9593 - val_loss: 1.4156 - val_accuracy: 0.7692\n",
      "Epoch 109/200\n",
      "313/313 [==============================] - 40s 126ms/step - loss: 0.4810 - accuracy: 0.9655 - val_loss: 1.7269 - val_accuracy: 0.7116\n",
      "Epoch 110/200\n",
      "313/313 [==============================] - 38s 122ms/step - loss: 0.4942 - accuracy: 0.9610 - val_loss: 1.4892 - val_accuracy: 0.7497\n",
      "Epoch 111/200\n",
      "313/313 [==============================] - 36s 115ms/step - loss: 0.4793 - accuracy: 0.9654 - val_loss: 1.7138 - val_accuracy: 0.7396\n",
      "Epoch 112/200\n",
      "313/313 [==============================] - 38s 122ms/step - loss: 0.4893 - accuracy: 0.9629 - val_loss: 1.6240 - val_accuracy: 0.7447\n",
      "Epoch 113/200\n",
      "313/313 [==============================] - 39s 124ms/step - loss: 0.4961 - accuracy: 0.9611 - val_loss: 1.4828 - val_accuracy: 0.7645\n",
      "Epoch 114/200\n",
      "313/313 [==============================] - 39s 124ms/step - loss: 0.4720 - accuracy: 0.9682 - val_loss: 1.5921 - val_accuracy: 0.7407\n",
      "Epoch 115/200\n",
      "313/313 [==============================] - 35s 113ms/step - loss: 0.4844 - accuracy: 0.9639 - val_loss: 1.6327 - val_accuracy: 0.7390\n",
      "Epoch 116/200\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 0.5008 - accuracy: 0.9595 - val_loss: 2.2351 - val_accuracy: 0.6570\n",
      "Epoch 117/200\n",
      "313/313 [==============================] - 33s 107ms/step - loss: 0.4687 - accuracy: 0.9699 - val_loss: 1.6291 - val_accuracy: 0.7474\n",
      "Epoch 118/200\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 0.4964 - accuracy: 0.9598 - val_loss: 1.9179 - val_accuracy: 0.6579\n",
      "Epoch 119/200\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 0.4840 - accuracy: 0.9639 - val_loss: 1.5726 - val_accuracy: 0.7335\n",
      "Epoch 120/200\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.4758 - accuracy: 0.9664 - val_loss: 1.3897 - val_accuracy: 0.7839\n",
      "Epoch 121/200\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.4693 - accuracy: 0.9671 - val_loss: 1.3461 - val_accuracy: 0.7832\n",
      "Epoch 122/200\n",
      "313/313 [==============================] - 34s 107ms/step - loss: 0.4734 - accuracy: 0.9652 - val_loss: 1.7383 - val_accuracy: 0.7240\n",
      "Epoch 123/200\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 0.4786 - accuracy: 0.9642 - val_loss: 1.3731 - val_accuracy: 0.7563\n",
      "Epoch 124/200\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 0.4800 - accuracy: 0.9631 - val_loss: 1.5089 - val_accuracy: 0.7537\n",
      "Epoch 125/200\n",
      "313/313 [==============================] - 34s 110ms/step - loss: 0.4690 - accuracy: 0.9666 - val_loss: 1.6789 - val_accuracy: 0.7376\n",
      "Epoch 126/200\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 0.4894 - accuracy: 0.9606 - val_loss: 1.4426 - val_accuracy: 0.7700\n",
      "Epoch 127/200\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.4688 - accuracy: 0.9675 - val_loss: 2.4420 - val_accuracy: 0.6261\n",
      "Epoch 128/200\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.4601 - accuracy: 0.9680 - val_loss: 1.5622 - val_accuracy: 0.7488\n",
      "Epoch 129/200\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 0.4960 - accuracy: 0.9576 - val_loss: 1.6692 - val_accuracy: 0.7315\n",
      "Epoch 130/200\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.4744 - accuracy: 0.9675 - val_loss: 1.4180 - val_accuracy: 0.7648\n",
      "Epoch 131/200\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 0.4654 - accuracy: 0.9682 - val_loss: 1.5845 - val_accuracy: 0.7415\n",
      "Epoch 132/200\n",
      "313/313 [==============================] - 34s 107ms/step - loss: 0.4882 - accuracy: 0.9608 - val_loss: 1.3982 - val_accuracy: 0.7453\n",
      "Epoch 133/200\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 0.4763 - accuracy: 0.9649 - val_loss: 1.4896 - val_accuracy: 0.7321\n",
      "Epoch 134/200\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 0.4757 - accuracy: 0.9665 - val_loss: 1.3181 - val_accuracy: 0.7723\n",
      "Epoch 135/200\n",
      "313/313 [==============================] - 34s 110ms/step - loss: 0.4664 - accuracy: 0.9675 - val_loss: 1.5530 - val_accuracy: 0.7757\n",
      "Epoch 136/200\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 0.4702 - accuracy: 0.9656 - val_loss: 1.3578 - val_accuracy: 0.7695\n",
      "Epoch 137/200\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.4776 - accuracy: 0.9641 - val_loss: 1.5945 - val_accuracy: 0.7490\n",
      "Epoch 138/200\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 0.4674 - accuracy: 0.9688 - val_loss: 1.3918 - val_accuracy: 0.7634\n",
      "Epoch 139/200\n",
      "313/313 [==============================] - 34s 107ms/step - loss: 0.4499 - accuracy: 0.9713 - val_loss: 1.2783 - val_accuracy: 0.7938\n",
      "Epoch 140/200\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.4585 - accuracy: 0.9686 - val_loss: 2.0842 - val_accuracy: 0.6630\n",
      "Epoch 141/200\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.4853 - accuracy: 0.9603 - val_loss: 1.3381 - val_accuracy: 0.7645\n",
      "Epoch 142/200\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 0.4581 - accuracy: 0.9701 - val_loss: 1.5028 - val_accuracy: 0.7329\n",
      "Epoch 143/200\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.4638 - accuracy: 0.9659 - val_loss: 1.3635 - val_accuracy: 0.7725\n",
      "Epoch 144/200\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.4715 - accuracy: 0.9652 - val_loss: 1.7886 - val_accuracy: 0.7115\n",
      "Epoch 145/200\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.4584 - accuracy: 0.9688 - val_loss: 1.7648 - val_accuracy: 0.7285\n",
      "Epoch 146/200\n",
      "313/313 [==============================] - 34s 107ms/step - loss: 0.4590 - accuracy: 0.9679 - val_loss: 1.3527 - val_accuracy: 0.7751\n",
      "Epoch 147/200\n",
      "313/313 [==============================] - 33s 107ms/step - loss: 0.4661 - accuracy: 0.9650 - val_loss: 1.4006 - val_accuracy: 0.7811\n",
      "Epoch 148/200\n",
      "313/313 [==============================] - 34s 107ms/step - loss: 0.4587 - accuracy: 0.9682 - val_loss: 1.8546 - val_accuracy: 0.7069\n",
      "Epoch 149/200\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.4580 - accuracy: 0.9680 - val_loss: 1.8266 - val_accuracy: 0.7071\n",
      "Epoch 150/200\n",
      "313/313 [==============================] - 34s 107ms/step - loss: 0.4693 - accuracy: 0.9647 - val_loss: 1.6676 - val_accuracy: 0.7341\n",
      "Epoch 151/200\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.4705 - accuracy: 0.9654 - val_loss: 1.7619 - val_accuracy: 0.7253\n",
      "Epoch 152/200\n",
      "313/313 [==============================] - 34s 107ms/step - loss: 0.4544 - accuracy: 0.9707 - val_loss: 1.2739 - val_accuracy: 0.8023\n",
      "Epoch 153/200\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.4543 - accuracy: 0.9688 - val_loss: 1.8577 - val_accuracy: 0.7132\n",
      "Epoch 154/200\n",
      "313/313 [==============================] - 33s 107ms/step - loss: 0.4722 - accuracy: 0.9638 - val_loss: 1.3247 - val_accuracy: 0.7709\n",
      "Epoch 155/200\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 0.4318 - accuracy: 0.9774 - val_loss: 1.3088 - val_accuracy: 0.7868\n",
      "Epoch 156/200\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 0.4559 - accuracy: 0.9662 - val_loss: 1.9478 - val_accuracy: 0.7139\n",
      "Epoch 157/200\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.4880 - accuracy: 0.9573 - val_loss: 1.1668 - val_accuracy: 0.8016\n",
      "Epoch 158/200\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 0.4565 - accuracy: 0.9702 - val_loss: 1.4023 - val_accuracy: 0.7820\n",
      "Epoch 159/200\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.4356 - accuracy: 0.9743 - val_loss: 1.5849 - val_accuracy: 0.7526\n",
      "Epoch 160/200\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.4767 - accuracy: 0.9604 - val_loss: 1.3394 - val_accuracy: 0.7857\n",
      "Epoch 161/200\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 0.4757 - accuracy: 0.9641 - val_loss: 1.5860 - val_accuracy: 0.7334\n",
      "Epoch 162/200\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 0.4452 - accuracy: 0.9729 - val_loss: 1.5429 - val_accuracy: 0.7284\n",
      "Epoch 163/200\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 0.4493 - accuracy: 0.9702 - val_loss: 1.4008 - val_accuracy: 0.7616\n",
      "Epoch 164/200\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.4765 - accuracy: 0.9619 - val_loss: 1.7146 - val_accuracy: 0.7105\n",
      "Epoch 165/200\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 0.4684 - accuracy: 0.9663 - val_loss: 1.6633 - val_accuracy: 0.7330\n",
      "Epoch 166/200\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 0.4389 - accuracy: 0.9747 - val_loss: 1.4623 - val_accuracy: 0.7608\n",
      "Epoch 167/200\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 0.4520 - accuracy: 0.9688 - val_loss: 1.5062 - val_accuracy: 0.7475\n",
      "Epoch 168/200\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 0.4665 - accuracy: 0.9644 - val_loss: 1.4090 - val_accuracy: 0.7683\n",
      "Epoch 169/200\n",
      "313/313 [==============================] - 34s 110ms/step - loss: 0.4544 - accuracy: 0.9688 - val_loss: 1.8459 - val_accuracy: 0.7227\n",
      "Epoch 170/200\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.4527 - accuracy: 0.9682 - val_loss: 1.4531 - val_accuracy: 0.7246\n",
      "Epoch 171/200\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.4640 - accuracy: 0.9668 - val_loss: 1.5021 - val_accuracy: 0.7564\n",
      "Epoch 172/200\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 0.4387 - accuracy: 0.9740 - val_loss: 1.5788 - val_accuracy: 0.7447\n",
      "Epoch 173/200\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 0.4716 - accuracy: 0.9634 - val_loss: 1.9137 - val_accuracy: 0.6992\n",
      "Epoch 174/200\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 0.4579 - accuracy: 0.9684 - val_loss: 1.5010 - val_accuracy: 0.7440\n",
      "Epoch 175/200\n",
      "313/313 [==============================] - 34s 107ms/step - loss: 0.4536 - accuracy: 0.9682 - val_loss: 2.2918 - val_accuracy: 0.6663\n",
      "Epoch 176/200\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 0.4595 - accuracy: 0.9678 - val_loss: 1.4125 - val_accuracy: 0.7640\n",
      "Epoch 177/200\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 0.4372 - accuracy: 0.9740 - val_loss: 1.5446 - val_accuracy: 0.7637\n",
      "Epoch 178/200\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 0.4613 - accuracy: 0.9653 - val_loss: 1.5042 - val_accuracy: 0.7601\n",
      "Epoch 179/200\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.4562 - accuracy: 0.9684 - val_loss: 1.4775 - val_accuracy: 0.7663\n",
      "Epoch 180/200\n",
      "313/313 [==============================] - 34s 107ms/step - loss: 0.4500 - accuracy: 0.9703 - val_loss: 1.3355 - val_accuracy: 0.7797\n",
      "Epoch 181/200\n",
      "313/313 [==============================] - 33s 107ms/step - loss: 0.4607 - accuracy: 0.9665 - val_loss: 1.5295 - val_accuracy: 0.7451\n",
      "Epoch 182/200\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.4627 - accuracy: 0.9679 - val_loss: 1.4166 - val_accuracy: 0.7666\n",
      "Epoch 183/200\n",
      "313/313 [==============================] - 33s 107ms/step - loss: 0.4395 - accuracy: 0.9733 - val_loss: 1.6935 - val_accuracy: 0.7140\n",
      "Epoch 184/200\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 0.4680 - accuracy: 0.9632 - val_loss: 1.4564 - val_accuracy: 0.7575\n",
      "Epoch 185/200\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.4521 - accuracy: 0.9704 - val_loss: 1.7626 - val_accuracy: 0.7330\n",
      "Epoch 186/200\n",
      "313/313 [==============================] - 33s 107ms/step - loss: 0.4416 - accuracy: 0.9721 - val_loss: 1.8074 - val_accuracy: 0.7028\n",
      "Epoch 187/200\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.4541 - accuracy: 0.9671 - val_loss: 1.6515 - val_accuracy: 0.7434\n",
      "Epoch 188/200\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.4405 - accuracy: 0.9721 - val_loss: 1.3891 - val_accuracy: 0.7747\n",
      "Epoch 189/200\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 0.4437 - accuracy: 0.9707 - val_loss: 1.4528 - val_accuracy: 0.7643\n",
      "Epoch 190/200\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 0.4638 - accuracy: 0.9645 - val_loss: 1.7011 - val_accuracy: 0.7078\n",
      "Epoch 191/200\n",
      "313/313 [==============================] - 35s 113ms/step - loss: 0.4481 - accuracy: 0.9703 - val_loss: 1.4999 - val_accuracy: 0.7624\n",
      "Epoch 192/200\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.4478 - accuracy: 0.9700 - val_loss: 1.7271 - val_accuracy: 0.7251\n",
      "Epoch 193/200\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.4487 - accuracy: 0.9699 - val_loss: 1.2735 - val_accuracy: 0.7914\n",
      "Epoch 194/200\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 0.4548 - accuracy: 0.9681 - val_loss: 1.9894 - val_accuracy: 0.6980\n",
      "Epoch 195/200\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.4558 - accuracy: 0.9681 - val_loss: 1.3556 - val_accuracy: 0.7736\n",
      "Epoch 196/200\n",
      "313/313 [==============================] - 35s 110ms/step - loss: 0.4481 - accuracy: 0.9703 - val_loss: 1.2678 - val_accuracy: 0.7830\n",
      "Epoch 197/200\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.4428 - accuracy: 0.9714 - val_loss: 1.7008 - val_accuracy: 0.7400\n",
      "Epoch 198/200\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.4502 - accuracy: 0.9698 - val_loss: 1.4261 - val_accuracy: 0.7666\n",
      "Epoch 199/200\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.4501 - accuracy: 0.9687 - val_loss: 1.6713 - val_accuracy: 0.7360\n",
      "Epoch 200/200\n",
      "313/313 [==============================] - 34s 110ms/step - loss: 0.4571 - accuracy: 0.9679 - val_loss: 1.4784 - val_accuracy: 0.7651\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9de1bef4f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "# model.compile(loss ='categorical_crossentropy',\n",
    "#               optimizer ='adam',\n",
    "#               metrics =['accuracy'])\n",
    "lr = 0.1\n",
    "optimizer = SGD(learning_rate=lr, momentum=0.9)\n",
    "model.compile(optimizer=optimizer, \n",
    "              loss=\"sparse_categorical_crossentropy\", \n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "# train model\n",
    "model.fit(x_train, \n",
    "          y_train, \n",
    "          batch_size=batch_size, \n",
    "          epochs=n_epochs,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a9b8fda-5395-4334-8e95-dd7029b558d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 3s 31ms/step - loss: 1.5790 - accuracy: 0.7451\n",
      "Original Accuracy:  [1.5790451765060425, 0.7451000213623047]\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "score = model.evaluate(x_test, \n",
    "                       y_test, \n",
    "                       batch_size=batch_size)\n",
    "\n",
    "print(\"Original Accuracy: \",score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cd8935b-8c39-4289-96ec-587710b0db57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "model_type = dataset + \"--\" + model_arch\n",
    "model_instance = model_type + \"-\" + str(seed)\n",
    "model_filename = model_instance + \".h5\"\n",
    "model_subdir = pathlib.Path(MODELS_FOLDER / model.name)\n",
    "pathlib.Path(model_subdir).mkdir(parents=True, exist_ok=True)\n",
    "model_file = str(pathlib.Path(model_subdir/ model_filename))\n",
    "model.save(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88df8c89-43a8-4b9f-8ba0-4c53c6b0b326",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet56\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 32, 32, 16)   448         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 32, 32, 16)  64          ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 32, 32, 16)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 32, 32, 16)   2320        ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 32, 32, 16)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 32, 32, 16)   2320        ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 32, 32, 16)   0           ['activation[0][0]',             \n",
      "                                                                  'batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 32, 32, 16)   0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 32, 32, 16)   2320        ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 32, 32, 16)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 32, 32, 16)   2320        ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 32, 32, 16)   0           ['activation_2[0][0]',           \n",
      "                                                                  'batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 32, 32, 16)   0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 32, 32, 16)   2320        ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 32, 32, 16)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 32, 32, 16)   2320        ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 32, 32, 16)   0           ['activation_4[0][0]',           \n",
      "                                                                  'batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 32, 32, 16)   0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 32, 32, 16)   2320        ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 32, 32, 16)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 32, 32, 16)   2320        ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 32, 32, 16)   0           ['activation_6[0][0]',           \n",
      "                                                                  'batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 32, 32, 16)   0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 32, 32, 16)   2320        ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 32, 32, 16)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 32, 32, 16)   2320        ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 32, 32, 16)  64          ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 32, 32, 16)   0           ['activation_8[0][0]',           \n",
      "                                                                  'batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 32, 32, 16)   0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 32, 32, 16)   2320        ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 32, 32, 16)  64          ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 32, 32, 16)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 32, 32, 16)   2320        ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 32, 32, 16)  64          ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 32, 32, 16)   0           ['activation_10[0][0]',          \n",
      "                                                                  'batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 32, 32, 16)   0           ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 32, 32, 16)   2320        ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 32, 32, 16)  64          ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 32, 32, 16)   0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 32, 32, 16)   2320        ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 32, 32, 16)  64          ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 32, 32, 16)   0           ['activation_12[0][0]',          \n",
      "                                                                  'batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 32, 32, 16)   0           ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 32, 32, 16)   2320        ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 32, 32, 16)  64          ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 32, 32, 16)   0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 32, 32, 16)   2320        ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 32, 32, 16)  64          ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 32, 32, 16)   0           ['activation_14[0][0]',          \n",
      "                                                                  'batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 32, 32, 16)   0           ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 32, 32, 16)   2320        ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 32, 32, 16)  64          ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 32, 32, 16)   0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 32, 32, 16)   2320        ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 32, 32, 16)  64          ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 32, 32, 16)   0           ['activation_16[0][0]',          \n",
      "                                                                  'batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 32, 32, 16)   0           ['add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 16, 16, 32)   4640        ['activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 16, 16, 32)  128         ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 16, 16, 32)   0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 16, 16, 32)   544         ['activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 16, 16, 32)  128         ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 16, 16, 32)   0           ['conv2d_21[0][0]',              \n",
      "                                                                  'batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 16, 16, 32)   0           ['add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 16, 16, 32)  128         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 16, 16, 32)   0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_21[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 16, 16, 32)  128         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 16, 16, 32)   0           ['activation_20[0][0]',          \n",
      "                                                                  'batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 16, 16, 32)   0           ['add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 16, 16, 32)  128         ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 16, 16, 32)   0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 16, 16, 32)  128         ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 16, 16, 32)   0           ['activation_22[0][0]',          \n",
      "                                                                  'batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 16, 16, 32)   0           ['add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_24[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 16, 16, 32)  128         ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 16, 16, 32)   0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 16, 16, 32)  128         ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 16, 16, 32)   0           ['activation_24[0][0]',          \n",
      "                                                                  'batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 16, 16, 32)   0           ['add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_26[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 16, 16, 32)  128         ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 16, 16, 32)   0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 16, 16, 32)  128         ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 16, 16, 32)   0           ['activation_26[0][0]',          \n",
      "                                                                  'batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 16, 16, 32)   0           ['add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 16, 16, 32)  128         ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 16, 16, 32)   0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_29[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 16, 16, 32)  128         ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 16, 16, 32)   0           ['activation_28[0][0]',          \n",
      "                                                                  'batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 16, 16, 32)   0           ['add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_30[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 16, 16, 32)  128         ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 16, 16, 32)   0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 16, 16, 32)  128         ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 16, 16, 32)   0           ['activation_30[0][0]',          \n",
      "                                                                  'batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 16, 16, 32)   0           ['add_15[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 16, 16, 32)  128         ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 16, 16, 32)   0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_33[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 16, 16, 32)  128         ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 16, 16, 32)   0           ['activation_32[0][0]',          \n",
      "                                                                  'batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 16, 16, 32)   0           ['add_16[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 16, 16, 32)  128         ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 16, 16, 32)   0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 16, 16, 32)  128         ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, 16, 16, 32)   0           ['activation_34[0][0]',          \n",
      "                                                                  'batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 16, 16, 32)   0           ['add_17[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 8, 8, 64)     18496       ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 8, 8, 64)    256         ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 8, 8, 64)     2112        ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 8, 8, 64)    256         ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_18 (Add)                   (None, 8, 8, 64)     0           ['conv2d_40[0][0]',              \n",
      "                                                                  'batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 8, 8, 64)     0           ['add_18[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_38[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 8, 8, 64)    256         ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 8, 8, 64)    256         ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_19 (Add)                   (None, 8, 8, 64)     0           ['activation_38[0][0]',          \n",
      "                                                                  'batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 8, 8, 64)     0           ['add_19[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_40[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 8, 8, 64)    256         ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 8, 8, 64)    256         ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_20 (Add)                   (None, 8, 8, 64)     0           ['activation_40[0][0]',          \n",
      "                                                                  'batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 8, 8, 64)     0           ['add_20[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 8, 8, 64)    256         ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_43[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 8, 8, 64)    256         ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_21 (Add)                   (None, 8, 8, 64)     0           ['activation_42[0][0]',          \n",
      "                                                                  'batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 8, 8, 64)     0           ['add_21[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 8, 8, 64)    256         ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 8, 8, 64)    256         ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_22 (Add)                   (None, 8, 8, 64)     0           ['activation_44[0][0]',          \n",
      "                                                                  'batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 8, 8, 64)     0           ['add_22[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 8, 8, 64)    256         ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 8, 8, 64)    256         ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_23 (Add)                   (None, 8, 8, 64)     0           ['activation_46[0][0]',          \n",
      "                                                                  'batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 8, 8, 64)     0           ['add_23[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_48[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 8, 8, 64)    256         ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 8, 8, 64)    256         ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_24 (Add)                   (None, 8, 8, 64)     0           ['activation_48[0][0]',          \n",
      "                                                                  'batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 8, 8, 64)     0           ['add_24[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_50[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 8, 8, 64)    256         ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 8, 8, 64)    256         ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_25 (Add)                   (None, 8, 8, 64)     0           ['activation_50[0][0]',          \n",
      "                                                                  'batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 8, 8, 64)     0           ['add_25[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 8, 8, 64)    256         ['conv2d_55[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_53[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 8, 8, 64)    256         ['conv2d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_26 (Add)                   (None, 8, 8, 64)     0           ['activation_52[0][0]',          \n",
      "                                                                  'batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 8, 8, 64)     0           ['add_26[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 64)          0           ['activation_54[0][0]']          \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 64)           0           ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 10)           650         ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 861,770\n",
      "Trainable params: 857,706\n",
      "Non-trainable params: 4,064\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650f5fc3-cf01-4b5e-8a11-dc0546cbf52b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
